\chapter{Výsledky}
% V následující kapitole porovnáme tři popisované algoritmy. 

\section{Vlastnosti algoritmů}
Při srovnávání algoritmů budeme používat několik kritérií. První hodnotou je maximální počet pokusů, které algoritmus potřebuje k nalezení libovolného tajného kódu $v \in H_{n,k}$. K nalezení maximálního počtu pokusů stačí vyzkoušet chod algoritmu na všech tajných kódech $v \in H_{n,k}$. V sekci se stromem algoritmu jsme ukázali, že tato hodnota je ekvivalentní největší vzdálenosti listu od kořene ve stromě algoritmu ve smyslu počtu hran.

\begin{definice}[Maximální počet pokusů]\label{defmaxpocetpokusu}
    Nechť $T$ je strom algoritmu pro nějaký algoritmus řešící hru [n,k]-Mastermind. Maximální počet pokusů tohoto algoritmu definujeme jako délku nejdelší cesty od kořene $T$ k nějakému listu $T$. 
\end{definice}

Druhý ukazatel, který u algoritmů budeme srovnávat je průměrný počet pokusů na hru. Ten lze opět odvodit ze stromu algoritmu.

\begin{definice}[Průměrný počet pokusů]\label{defprumpocetpokusu}
    Nechť $T = (V,E)$ je strom algoritmu pro nějaký algoritmus řešící hru [n,k]-Mastermind. Pro list $A$ označíme $d(A)$ jeho vzdálenost od kořene ve smyslu počtu hran. Průměrný počet pokusů algoritmu definujeme jako 
    \[\frac{1}{k^n}\sum_{A\in V, A \text{ list}} d(A).\]
\end{definice}

Posledním kritériem, kterého si budeme u algoritmů všímat je výběr prvního tahu. Zajímá nás, jestli první tah, který algoritmus zvolí, je optimální. Tedy zda neexistuje jiný první pokus, který by s následným použitím algoritmu vracel lepší výsledky. Tuto vlastnost pojmenujeme \emph{konzistence}.

V případě [4,6]-Mastermindu budeme konzistenci zkoumat pro pět počátečních kódů $1111$, $1112$, $1122$, $1123$, $1234$. Obhajujeme to tím, že neexistuje kód, který by vytvořil nějakou jinou valuaci v prvním tahu než tyto kódy. To plyne z toho, že každý kód vznikne nějakou substitucí barev a permutací pozic těchto pěti kódů. Tyto operace nezmění velikosti potomků ${H_{4,6}}_{u,r}$, protože jednotlivé pozice a barvy jsou rovnoměrně rozloženy v celém prostoru kódů. A protože tři použité valuace vycházejí právě z velikostí potomků, jejich hodnoty se nezmění. 

% V sekci $4.5$ diskutujeme možný vliv výběru lexikograficky vyššího prvního tahu z důvodu následného výběru lexikograficky minimálních kódů ve všech algoritmech.

V tabulce \ref{tabvaluaceprvnichtahu} jsou zobrazeny valuace pěti zmíněných kódů vzhledem k $H_{4,6}$. Nejlepší valuace prvního pokusu podle zvolené strategie v konkrétním algoritmu je zobrazena tučně. 


\begin{table}[h]
\centering
\begin{tabular}{l l l l l l}
\toprule
kód & 1111 & 1112 & 1122 & 1123 & 1234 \\
\midrule

Maximum potomka & 625 & 317 & \textbf{256} & 276 & 312 \\
Entropie potomků & 1.50 & 2.69 & 2.89 & 3.04 & \textbf{3.06}\\

% [1.4984350761704437, 2.6934339172716406, 2.885102174947102, 3.0436979819559213, 3.0566709153318907]

%vážený průměr - $\sum_{i = 1}^{14} |S_i|  \cdot \pr (S_i)$ & 512.0 & 235.9 & 204.5 & \textbf{185.3} & 188.2 \\

% [511.9799382716049, 235.94907407407408, 204.53549382716048, 185.26851851851853, 188.18981481481484]

Počet potomků & 5 & 11 & 13 & \textbf{14} & \textbf{14} \\

\bottomrule
\multicolumn{6}{l}{\footnotesize \textit{Pozn:}
Entropie je zaokrouhlena na dvě desetinná místa.
%, vážený průměr na jedno.
}

\end{tabular}
\caption{Hodnoty valuace kódů pro první tah}
\label{tabvaluaceprvnichtahu}
\end{table}



\section{Způsob testování}
Výsledky algoritmů byly nalezeny vytvořením stromu algoritmu pro každou metodu. Strom byl sestavován postupně, kdy pro každý stav (vrchol na grafu) byl nalezen nejlepší další pokus podle zvolené valuace a strategie. Ve chvíli, kdy program dojde do listu hranou $(n,0)$, je uložena aktuální vzdálenost listu od kořene (počet pokusů potřebný k nalezení daného tajného kódu) do seznamu s počty pokusů. 
%V průběhu vytváření stromu byly zjišťovány vzdálenosti konečných stavů (listů) od kořene odpovídající počtu pokusů potřebných k uhádnutí daného kódu. 
Následně z těchto hodnot byly vypočten maximální a průměrný počet pokusů. Konzistence algoritmů byla nalezena sestrojením stromu algoritmu s pevně zvoleným prvním tahem.

Tento postup byl implementován v jazyce Python pro účel této práce. Zdrojový kód a jeho dokumentace je dostupný na GitHub \cite{Simsa_Strategies_for_Mastermind_2025}. 



% Výsledky algoritmů byly nalezeny pomocí programu napsaného v jazyce Python pro účel této práce \cite{Simsa_Strategies_for_Mastermind_2025}. Maximální a průměrné počty pokusů byly nalezeny za pomocí sestavení stromu řešení [4,6]-Mastermind jako na obrázku \ref{fig22minmax}. Strom byl sestavován postupně, kdy pro každý stav (vrchol na grafu) byl nalezen nejlepší další pokus. Ve chvíli, kdy program dojde do listu hranou $(n,0)$, uchová si aktuální počet pokusů potřebný k nalezení daného tajného kódu. Program končí ve chvíli, kdy je každý kód v listu. Nakonec se spočítá očekávaný a maximální počet pokusů ze zachovaných hodnot pro jednotlivé kódy.

% Existují dvě situace, pro které se stav dostane do listu. První je v případě, kdy stav je složen z více kódů a tedy nevíme, který z nich je tajný kódem. V případě, že algoritmus vybere jako další pokus kandidáta, může se stát, že tento kandidát byl dokonce tajným kódem. V tu chvíli máme štěstí a nalezli jsme počet pokusů, který potřebuje min-max algoritmus k nalezení tohoto tajného kódu. Druhá situace nastává, kdy stavem je jednoprvková množina s pouze jedním kódem. Zároveň ho min-max algoritmus zatím nezahrál. V tuto chvíli algoritmus ví, který kód je tajným, ale musí ho ještě zahrát, protože hra končí ve chvíli, kdy je zahraný tajný kód. 

\section{Výsledky algoritmů}

\subsubsection{Min-max}

Tabulka \ref{tabminmaxvysl} ukazuje výsledky Knuthova algoritmu v závislosti na volbě prvního pokusu. Tabulka \ref{tabvaluaceprvnichtahu} ukazuje valuace pěti použitých kódů. Min-max algoritmus tedy jako první tah volí kód $1122$. Maximální počet pokusů Min-max algoritmu je $5$ a tedy je v tomto směru optimální. Průměrně pak potřebuje $4.476$ pokusů. Při volbě jiného prvního tahu jsou ve všech případech oba výsledky horší. Min-max algoritmus je tedy konzistentní.

% Maximální počet pokusů, který min-max algoritmus (začínající kódem 1122) potřebuje na prolomení tajného kódu je $5$. Průměrně pak potřebuje $4.476$ pokusů. K porovnání jsou uvedeny maximální a průměrné počty pokusů pro jiné počáteční kódy. Mohli bychom totiž očekávat, že by průměrný nebo maximální počet pokusů byl menší pro jiný počáteční kód, jak bylo znázorněno v příkladu \ref{malyprikladminmax}. Nejlepších výsledků ale algoritmus dosahuje v při volbě prvního tahu $1122$, který odpovídá přirozenému výběru prvního tahu podle definice Knuthova algoritmu. 

\begin{table}[h]
\centering
\begin{tabular}{l l l l l l}
\toprule
první pokus & 1111 & 1112 & \textbf{1122} & 1123 & 1234 \\
\midrule

maximální počet pokusů 
& 6 & 6 & \textbf{5} & 6 & 6 \\

průměrný počet pokusů 
& 5.065 & 4.556 & \textbf{4.476} & 4.4776 & 4.4776\\
\bottomrule
\multicolumn{6}{l}{\footnotesize \textit{Pozn:}
Průměrný počet pokusů je zaokrouhlen na $3$ desetinná místa}
\end{tabular}
\caption{Výsledky Min-max algoritmu}\label{tabminmaxvysl}
\end{table}

\subsubsection{Max entropy}

Algoritmus Max entropy vybírá jako první pokus kód $1234$, protože tento kód dosahuje největší valuace entropie, jak znázorňuje tabulka \ref{tabvaluaceprvnichtahu}. Tabulka \ref{tabentropievysl} zobrazuje výsledky algoritmu Max entropy. Dosahuje průměrného počtu pokusů $4.415$, což je lepší výsledek než v případě Min-max algoritmu. Tento algoritmus ale nedokáže zaručit vítězství na pět pokusů.

Navíc, pokud by tento algoritmus volil počáteční kód $1123$, dosáhl by lepšího průměrného počtu pokusů, konkrétně $4.383$. Algoritmus Max entropy tedy není konzistentní. Vysvětlením by mohl být fakt, že entropie neodhaduje ideálně počet pokusů. Mohlo by to být tím, že rozdělení množiny $K$ do potomků $K_{u,r}$ není rovnoměrné. Entropie tedy nedokáže správně odhadnout rozložení množin kandidátů o dva tahy dál. 
%Kdybychom uvažovali valuace, které by srovnávali velikosti potomků do hloubky $2$. 
\begin{table}[h]
\centering
\begin{tabular}{l l l l l l}
\toprule
první pokus & 1111 & 1112 & 1122 & 1123 & \textbf{1234} \\
\midrule

maximální počet pokusů 
& 6 & 6 & 6 & 6 & 6 \\

průměrný počet pokusů 
& 4.911 & 4.496 & 4.428 & \textbf{4.383} & 4.415 \\
\bottomrule
\multicolumn{6}{l}{\footnotesize \textit{Pozn:}
Průměrný počet pokusů je zaokrouhlen na $3$ desetinná místa}
\end{tabular}
\caption{Výsledky algoritmu Max entropy}\label{tabentropievysl}
\end{table}



\subsubsection{Most parts}
Algoritmus Most parts volí jako první tah kód $1123$ (plyne z tabulky \ref{tabvaluaceprvnichtahu}) a dosahuje průměrného počtu pokusů $4.373$. Tento výsledek, zobrazený v tabulce \ref{tabcastivysl}, je ze všech porovnávaných algoritmů nejlepší. Maximální počet pokusů je ale opět horší než u algoritmu Min-max, a to 6. Most parts algoritmus je konzistentní, protože průměrné počty pokusů při odlišném prvním tahu jsou vyšší.


\begin{table}[h]
\centering
\begin{tabular}{l l l l l l}
\toprule
první pokus & 1111 & 1112 & 1122 & \textbf{1123} & 1234 \\
\midrule

maximální počet pokusů 
& 7 & 6 & 6 & 6 & 6 \\

průměrný počet pokusů 
& 4.911 & 4.503 & 4.420 & \textbf{4.373} & 4.444\\
\bottomrule
\multicolumn{6}{l}{\footnotesize \textit{Pozn:}
Průměrný počet pokusů je zaokrouhlen na $3$ desetinná místa}
\end{tabular}
\caption{Výsledky algoritmu Most parts}\label{tabcastivysl}
\end{table}


% \subsection{Očekávaný počet}
% Případná čtvrtá strategie...
% \begin{table}[h]
% \centering
% \begin{tabular}{l l l l l l}
% \toprule
% první pokus & 1111 & 1112 & 1122 & 1123 & 1234 \\
% \midrule

% maximální počet pokusů 
% & 6 & 6 & 5 & 6 & 6 \\

% průměrný počet pokusů 
% & 4.911 & 4.529 & 4.453 & 4.394 & 4.434 \\
% \bottomrule
% \multicolumn{6}{l}{\footnotesize \textit{Pozn:}
% Průměrný počet pokusů je zaokrouhlen na $3$ desetinná místa}
% \end{tabular}
% \caption{Výsledky algoritmu s očekávaným počtem kandidátů}\label{tabminmaxvysl}
% \end{table}

\subsubsection{Srovnání algoritmů}
Nejlepší maximální počet pokusů v případě Min-max algoritmu dává smysl, protože algoritmus minimalizuje maximální počet kódů v potomcích. Algoritmus Most parts dosáhl ze všech zmíněných algoritmů nejlepšího průměrného počtu pokusů. B. Kooi \cite{kooi} srovnává svůj algoritmus Most parts s Min-max algoritmem z hlediska jejich stromů algoritmů následovně. Min-max algoritmus zkoumá pouze hloubku stromu ve smyslu maximálního počtu kandidátů. Most parts algoritmus naopak hledá strom, který bude nejširší z hlediska počtu neprázdných pokračování. 

Algoritmus Max entropy dosahuje, možná překvapivě, o dost horšího průměrného počtu pokusů v porovnání s algoritmem Most parts. Je možné, že to je kvůli nešťastné volbě prvního tahu v případě čtyř pozic a šesti barev. G. Ville \cite{ville2013optimalmastermind47strategy} totiž ukázal výsledky zmíněných algoritmů v [4,7] a [5,8]-Mastermindu, kde Max entropy dosahuje naopak nejlepšího průměrného počtu pokusů. 




% Výsledek algoritmu Most parts je do jisté míry překvapivý. Most parts algoritmus totiž maximalizuje pravděpodobnost, že tajný kód v dalším kole uhodneme a nijak se nesnaží odhadnout očekávaný počet pokusů. Domnívám se, že 

% Zároveň fakt, že zbylé algoritmy dosahují lepšího průměrného počtu pokusů také odpovídá tomu, že optimalizují nějakou očekávanou hodnotu následujících stavů. V případě algoritmu Max entropy to je očekávaná hodnota počtu otázek. 

\section{Varianty algoritmů}
\subsubsection{Volba pokusů pouze z kandidátů}
Všechny algoritmy uvedené do této chvíle vybíraly následující pokus ze všech kódů $u\in H_{n,k}$. Předpokládejme, že se nacházíme ve stavu $P$ s množinou kandidátů na tajný kód $K$. Pokud zahrajeme kód, který nenáleží do množiny $K$, nemáme šanci tajný kód v tomto kole prolomit. Logickou variantou algoritmů je způsob, který povoluje výběr dalšího pokusu pouze z množiny kandidátů stavu. V základním algoritmu \ref{alg-default} by množina $U$ na řádce $8$ měla tvar
\[U = \{u \in K \mid f_K(u) = F(f_K)\}.\]
Níže uvádíme výsledky algoritmů volící pouze kandidáty aplikované na [4,6]-Mastermind. Výsledky byly dosaženy stejným postupem jako u algoritmů výše, tedy postupným sestrojením stromu algoritmů. 

\begin{table}[h]
\centering
\begin{tabular}{l l l l}
\toprule
první pokus & Min-max & Max entropy & Počet potomků  \\
\midrule

maximální počet pokusů 
& 6 & 6 & 7  \\

průměrný počet pokusů 
& 4.497 & 4.465 & 4.399 \\
\bottomrule
\multicolumn{4}{l}{\footnotesize \textit{Pozn:}
Průměrný počet pokusů je zaokrouhlen na $3$ desetinná místa}
\end{tabular}
\caption{Výsledky algoritmů volící pouze kandidáty}\label{tabminmaxvysl}
\end{table}

Průměrný počet pokusů se zhoršil ve všech algoritmech, v algoritmu min-max a Max parts ze zhoršil i maximální počet pokusů. Tato volba algoritmů ale zmenší časovou složitost algoritmů. To plyne z toho, že algoritmus v každém stavu algoritmus neporovnává všechny kódy ale pouze kandidáty. 

% \begin{tvrz}
%     Uvažujme algoritmus \ref{alg-default} s výběrem množiny $U$ na řádku $7$ podle následujícího předpisu.
%     \[U = \{u \in K \mid f_K(u) = F(f_K)\}\]
%     Potom tento algoritmus má časovou složitost 
%      \[O \left( \sum_{j = 1}^z  m_j^2 \cdot n^2 \cdot \frac{n^2 + 3n}{2}\right)\]
% \end{tvrz}
% \begin{dukaz}
%     Tvrzení plyne z tvrzení ...
% \end{dukaz}

\subsubsection{Vícekrokové algoritmy}
Všechny popisované algoritmy používaly valuace, které zkoumají rozložení kandidátů u potomků daného stavu. Zkoumali tedy stavy o maximálně jednu hranu v grafu [n,k]-Mastermindu dál. Intuice napovídá, že pokud bychom zkoumali stavy o dvě hrany dál, algoritmy by měli lepší výsledky. Časová složitost těchto algoritmů by ale prudce rostla. Čím hlouběji bychom prohledávali strom [n,k]-Mastermindu, tím více bychom se blížili optimální metodě nalezené K. Koyamou a T. Laiem v roce 1993 \cite{koyama}. Jejich metoda dosahuje průměrného počtu pokusů $4.340$ s maximálním počtem pokusů $6$. V případě omezení maximálního počtu pokusů na $5$ dosáhli průměrného počtu pokusů $4.341$. 


\subsubsection{Jiná volba prvního tahu, případně popsat lexikografický výběr}



\section{Diskuze}
Poznámky:

\begin{itemize}
    \item Volba prvního tahu, který by obsahoval vyšší barvy by mohla být lepší, protože algoritmus volí lexikograficky menší kódy. Podobně by bylo možné náhodně promíchat seřazení všech kódů. 
    \item aplikace problému mastermind jsou diskutovány v článku doerr playing mastermind with many colours na straně 4
    \item odhad s entropií nefunguje tak dobře. Mohlo by to být silně nerovnoměrně rozdělenými kódy. Entropie neodpovídá ohodnocení, není to binární.

\end{itemize}




